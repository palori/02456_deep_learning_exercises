{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq - Encoder/Decoder networks\n",
    "In this exercise we'll have a deeper look into the ability to use multiple RNN's to infer and generate sequences of data.\n",
    "Specifically we will implement a Encoder-Decoder RNN based for a simple sequence to sequence translation task.\n",
    "This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "In the encoder-decoder structure one RNN (blue) encodes the input into a hidden representation, and a second RNN (red) uses this representation to predict the target values.\n",
    "An essential step is deciding how the encoder and decoder should communicate.\n",
    "In the simplest approach you use the last hidden state of the encoder to initialize the decoder.\n",
    "This is what we will do in this notebook, as shown here:\n",
    "\n",
    "![](./images/enc-dec.png)\n",
    "\n",
    "In this exercise we will translate from the words of number (e.g. 'nine') to the actual number (e.g. '9').\n",
    "The input for the Encoder RNN consists of words defining the number, whilst the output of such an encoding serves as input for the Decoder RNN that aims to generate generate a number. \n",
    "Our dataset is generated and consists of numbers and an End-of-Sentence (EOS) character ('#'). The data we want to generate should be like follows:\n",
    "\n",
    "```\n",
    "Examples: \n",
    "prediction  |  input\n",
    "991136#00 \t nine nine one one three six\n",
    "81771#000 \t eight one seven seven one\n",
    "3519614#0 \t three five one nine six one four\n",
    "26656#000 \t two six six five six\n",
    "60344#000 \t six zero three four four\n",
    "162885#00 \t one six two eight eight five\n",
    "78612625# \t seven eight six one two six two five\n",
    "9464710#0 \t nine four six four seven one zero\n",
    "191306#00 \t one nine one three zero six\n",
    "10160378# \t one zero one zero six three seven eight\n",
    "```\n",
    "\n",
    "Let us define the space of characters and numbers to be learned with the networks:\n",
    "\n",
    "```\n",
    "Number of valid characters: 27\n",
    "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t' '=11,\t'e'=12,\t'g'=13,\t'f'=14,\t'i'=15,\t'h'=16,\t'o'=17,\t'n'=18,\t's'=19,\t'r'=20,\t'u'=21,\t't'=22,\t'w'=23,\t'v'=24,\t'x'=25,\t'z'=26,\t\n",
    "Stop/start character = #\n",
    "```\n",
    "\n",
    "All represented characters and numbers as characters, gets mapped to an integer from 0-26. Our total space of valid characters consists of 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cpu\n"
     ]
    }
   ],
   "source": [
    "from data_generator import generate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_generator import generate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "\n",
    "NUM_INPUTS = 27 #No. of possible characters\n",
    "NUM_OUTPUTS = 11  # (0-9 + '#')\n",
    "\n",
    "### Hyperparameters and general configs\n",
    "MAX_SEQ_LEN = 8\n",
    "MIN_SEQ_LEN = 5\n",
    "BATCH_SIZE = 8\n",
    "TRAINING_SIZE = 8000\n",
    "LEARNING_RATE = 0.003\n",
    "\n",
    "# Hidden size of enc and dec need to be equal if last hidden of encoder becomes init hidden of decoder\n",
    "# Otherwise we would need e.g. a linear layer to map to a space with the correct dimension\n",
    "NUM_UNITS_ENC = NUM_UNITS_DEC = 48\n",
    "TEST_SIZE = 200\n",
    "EPOCHS = 10\n",
    "TEACHER_FORCING = False\n",
    "\n",
    "assert TRAINING_SIZE % BATCH_SIZE == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we won´t worry about data generation, but utilise a built function for this purpose. The function generates random data constained by the 27 characters described above.\n",
    "\n",
    "The encoder takes as input the embedded text strings generated from the *generate* function as given here above ie. 'nine' would become [18 15 18 12].\n",
    "Sequeneces are generated at random given settings of minima and maxima length, constrained by the dimensions of the two RNN´s architecture.\n",
    "We may visualise a subset of the data generated by running the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 3 from 3 iterations\r\n",
      "input types: int32 int32 int32 int32 int32\r\n",
      "Number of valid characters: 27\r\n",
      "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t'e'=11,\t'u'=12,\t'i'=13,\t'x'=14,\t'w'=15,\t' '=16,\t'r'=17,\t't'=18,\t'f'=19,\t'v'=20,\t'g'=21,\t'h'=22,\t'n'=23,\t's'=24,\t'o'=25,\t'z'=26,\t\r\n",
      "Stop/start character = #\r\n",
      "\r\n",
      "SAMPLE 0\r\n",
      "TEXT INPUTS:\t\t\t zero eight\r\n",
      "ENCODED INPUTS:\t\t\t [26 11 17 25 16 11 13 21 22 18  0  0  0  0  0  0  0  0  0]\r\n",
      "INPUTS SEQUENCE LENGTH:\t 10\r\n",
      "TEXT TARGETS INPUT:\t\t #08\r\n",
      "TEXT TARGETS OUTPUT:\t 08#\r\n",
      "ENCODED TARGETS INPUT:\t [10  0  8  0  0]\r\n",
      "ENCODED TARGETS OUTPUT:\t [ 0  8 10  0  0]\r\n",
      "TARGETS SEQUENCE LENGTH: 3\r\n",
      "TARGETS MASK:\t\t\t [1. 1. 1. 0. 0.]\r\n",
      "\r\n",
      "SAMPLE 1\r\n",
      "TEXT INPUTS:\t\t\t five zero two three\r\n",
      "ENCODED INPUTS:\t\t\t [19 13 20 11 16 26 11 17 25 16 18 15 25 16 18 22 17 11 11]\r\n",
      "INPUTS SEQUENCE LENGTH:\t 19\r\n",
      "TEXT TARGETS INPUT:\t\t #5023\r\n",
      "TEXT TARGETS OUTPUT:\t 5023#\r\n",
      "ENCODED TARGETS INPUT:\t [10  5  0  2  3]\r\n",
      "ENCODED TARGETS OUTPUT:\t [ 5  0  2  3 10]\r\n",
      "TARGETS SEQUENCE LENGTH: 5\r\n",
      "TARGETS MASK:\t\t\t [1. 1. 1. 1. 1.]\r\n",
      "\r\n",
      "SAMPLE 2\r\n",
      "TEXT INPUTS:\t\t\t six one\r\n",
      "ENCODED INPUTS:\t\t\t [24 13 14 16 25 23 11  0  0  0  0  0  0  0  0  0  0  0  0]\r\n",
      "INPUTS SEQUENCE LENGTH:\t 7\r\n",
      "TEXT TARGETS INPUT:\t\t #61\r\n",
      "TEXT TARGETS OUTPUT:\t 61#\r\n",
      "ENCODED TARGETS INPUT:\t [10  6  1  0  0]\r\n",
      "ENCODED TARGETS OUTPUT:\t [ 6  1 10  0  0]\r\n",
      "TARGETS SEQUENCE LENGTH: 3\r\n",
      "TARGETS MASK:\t\t\t [1. 1. 1. 0. 0.]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./data_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define the two RNN's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        rnn = nn.GRU\n",
    "        #rnn = nn.LSTM\n",
    "        self.rnn = rnn(hidden_size, hidden_size, batch_first=True)\n",
    "        #self.rnn = rnn(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Input shape [batch, seq_in_len]z\n",
    "        inputs = inputs.long()\n",
    "\n",
    "        # Embedded shape [batch, seq_in_len, embed]\n",
    "        embedded = self.embedding(inputs)\n",
    "        \n",
    "        # Output shape [batch, seq_in_len, embed]\n",
    "        # Hidden shape [1, batch, embed], last hidden state of the GRU cell\n",
    "        # We will feed this last hidden state into the decoder\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        return init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        rnn = nn.GRU\n",
    "        #rnn = nn.LSTM\n",
    "        self.rnn = rnn(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, inputs, hidden, output_len, teacher_forcing=False):\n",
    "        # Input shape: [batch, output_len]\n",
    "        # Hidden shape: [seq_len=1, batch_size, hidden_dim] (the last hidden state of the encoder)\n",
    "\n",
    "        if teacher_forcing:\n",
    "            dec_input = inputs\n",
    "            embed = self.embedding(dec_input)   # shape [batch, output_len, hidden_dim]\n",
    "            out, hidden = self.rnn(embed, hidden)\n",
    "            out = self.out(out)  # linear layer, out has now shape [batch, output_len, output_size]\n",
    "            output = F.log_softmax(out, -1)\n",
    "        else:\n",
    "            # Take the EOS character only, for the whole batch, and unsqueeze so shape is [batch, 1]\n",
    "            # This is the first input, then we will use as input the GRU output at the previous time step\n",
    "            dec_input = inputs[:, 0].unsqueeze(1)\n",
    "\n",
    "            output = []\n",
    "            for i in range(output_len):\n",
    "                out, hidden = self.rnn(self.embedding(dec_input), hidden)\n",
    "                out = self.out(out)  # linear layer, out has now shape [batch, 1, output_size]\n",
    "                out = F.log_softmax(out, -1)\n",
    "                output.append(out.squeeze(1))\n",
    "                out_symbol = torch.argmax(out, dim=2)   # shape [batch, 1]\n",
    "                dec_input = out_symbol   # feed the decoded symbol back into the recurrent unit at next step\n",
    "\n",
    "            output = torch.stack(output).permute(1, 0, 2)  # [batch_size x seq_len x output_size]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned representation from the *Encoder* gets propagated to the *Decoder* as the final hidden layer in the *Encoder* network is set as initialisation for the *Decoder*'s first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(encoder, decoder, x, t, t_in, criterion, max_t_len, teacher_forcing):\n",
    "    \"\"\"\n",
    "    Executes a forward pass through the whole model.\n",
    "\n",
    "    :param encoder:\n",
    "    :param decoder:\n",
    "    :param x: input to the encoder, shape [batch, seq_in_len]\n",
    "    :param t: target output predictions for decoder, shape [batch, seq_t_len]\n",
    "    :param criterion: loss function\n",
    "    :param max_t_len: maximum target length\n",
    "\n",
    "    :return: output (after log-softmax), loss, accuracy (per-symbol)\n",
    "    \"\"\"\n",
    "    # Run encoder and get last hidden state (and output)\n",
    "    batch_size = x.size(0)\n",
    "    enc_h = encoder.init_hidden(batch_size)\n",
    "    enc_out, enc_h = encoder(x, enc_h)\n",
    "\n",
    "    dec_h = enc_h  # Init hidden state of decoder as hidden state of encoder\n",
    "    dec_input = t_in\n",
    "    out = decoder(dec_input, dec_h, max_t_len, teacher_forcing)\n",
    "    out = out.permute(0, 2, 1)\n",
    "    # Shape: [batch_size x num_classes x out_sequence_len], with second dim containing log probabilities\n",
    "\n",
    "    loss = criterion(out, t)\n",
    "    pred = get_pred(log_probs=out)\n",
    "    accuracy = (pred == t).type(torch.FloatTensor).mean()\n",
    "    return out, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_t_len):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for batch_idx, (x, t, t_in) in enumerate(zip(inputs, targets, targets_in)):\n",
    "        \n",
    "        \n",
    "        # INSERT YOUR CODE HERE\n",
    "        x = x.type(torch.LongTensor)\n",
    "        t = t.type(torch.LongTensor)\n",
    "        t_in = t_in.type(torch.LongTensor)\n",
    "        \n",
    "        out, loss, accuracy = forward_pass(encoder, decoder,\n",
    "                                           x, t, t_in,\n",
    "                                           criterion,\n",
    "                                           max_target_len,\n",
    "                                           TEACHER_FORCING)\n",
    "        \n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Epoch {} [{}/{} ({:.0f}%)]\\tTraining loss: {:.4f} \\tTraining accuracy: {:.1f}%'.format(\n",
    "                epoch, batch_idx * len(x), TRAINING_SIZE,\n",
    "                100. * batch_idx * len(x) / TRAINING_SIZE, loss.item(),\n",
    "                100. * accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.long().to(device)\n",
    "        targets_in = targets_in.long().to(device)\n",
    "        out, loss, accuracy = forward_pass(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len,\n",
    "                                           teacher_forcing=TEACHER_FORCING)\n",
    "    return out, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_text(seq):\n",
    "    return \"\".join([str(to_np(i)) if to_np(i) != 10 else '#' for i in seq])\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "def get_pred(log_probs):\n",
    "    \"\"\"\n",
    "    Get class prediction (digit prediction) from the net's output (the log_probs)\n",
    "    :param log_probs: Tensor of shape [batch_size x n_classes x sequence_len]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 8000 from 8000 iterations\n",
      "Generated batch length 200 from 201 iterations\n",
      "Epoch 1 [0/8000 (0%)]\tTraining loss: 2.3547 \tTraining accuracy: 26.4%\n",
      "Epoch 1 [1600/8000 (20%)]\tTraining loss: 1.7755 \tTraining accuracy: 37.5%\n",
      "Epoch 1 [3200/8000 (40%)]\tTraining loss: 1.4749 \tTraining accuracy: 44.4%\n",
      "Epoch 1 [4800/8000 (60%)]\tTraining loss: 1.2795 \tTraining accuracy: 52.8%\n",
      "Epoch 1 [6400/8000 (80%)]\tTraining loss: 1.4059 \tTraining accuracy: 41.7%\n",
      "\n",
      "Test set: Average loss: 1.1845 \tAccuracy: 51.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "8088888#0 \t three eight six two zero four eight\n",
      "45435#000 \t four five one three four\n",
      "8555555## \t eight one seven six five five seven\n",
      "64111#000 \t six four one three nine\n",
      "93433333# \t five four three eight seven one two one\n",
      "019191#00 \t six five one zero seven nine\n",
      "75555#000 \t seven five four five two\n",
      "566666#00 \t nine five six eight six zero\n",
      "8199199#0 \t three nine zero one one nine eight\n",
      "4444448## \t two four nine four three six eight\n",
      "\n",
      "Epoch 2 [0/8000 (0%)]\tTraining loss: 1.1077 \tTraining accuracy: 51.4%\n",
      "Epoch 2 [1600/8000 (20%)]\tTraining loss: 1.2240 \tTraining accuracy: 47.2%\n",
      "Epoch 2 [3200/8000 (40%)]\tTraining loss: 1.2157 \tTraining accuracy: 56.9%\n",
      "Epoch 2 [4800/8000 (60%)]\tTraining loss: 1.3490 \tTraining accuracy: 37.5%\n",
      "Epoch 2 [6400/8000 (80%)]\tTraining loss: 1.1488 \tTraining accuracy: 54.2%\n",
      "\n",
      "Test set: Average loss: 1.1280 \tAccuracy: 54.167%\n",
      "\n",
      "Examples: prediction | input\n",
      "82428888# \t three eight six two zero four eight\n",
      "45334#000 \t four five one three four\n",
      "85555577# \t eight one seven six five five seven\n",
      "64111##00 \t six four one three nine\n",
      "92222222# \t five four three eight seven one two one\n",
      "651011##0 \t six five one zero seven nine\n",
      "52222#000 \t seven five four five two\n",
      "566660#00 \t nine five six eight six zero\n",
      "31931911# \t three nine zero one one nine eight\n",
      "44644388# \t two four nine four three six eight\n",
      "\n",
      "Epoch 3 [0/8000 (0%)]\tTraining loss: 0.9623 \tTraining accuracy: 56.9%\n",
      "Epoch 3 [1600/8000 (20%)]\tTraining loss: 1.0716 \tTraining accuracy: 54.2%\n",
      "Epoch 3 [3200/8000 (40%)]\tTraining loss: 1.0068 \tTraining accuracy: 61.1%\n",
      "Epoch 3 [4800/8000 (60%)]\tTraining loss: 0.9050 \tTraining accuracy: 55.6%\n",
      "Epoch 3 [6400/8000 (80%)]\tTraining loss: 0.9635 \tTraining accuracy: 62.5%\n",
      "\n",
      "Test set: Average loss: 0.9277 \tAccuracy: 63.056%\n",
      "\n",
      "Examples: prediction | input\n",
      "6840448#0 \t three eight six two zero four eight\n",
      "45334##00 \t four five one three four\n",
      "8755557## \t eight one seven six five five seven\n",
      "64933#000 \t six four one three nine\n",
      "54922223# \t five four three eight seven one two one\n",
      "6507799#0 \t six five one zero seven nine\n",
      "75552#000 \t seven five four five two\n",
      "966600#00 \t nine five six eight six zero\n",
      "3901199#0 \t three nine zero one one nine eight\n",
      "4614433#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 4 [0/8000 (0%)]\tTraining loss: 0.7557 \tTraining accuracy: 63.9%\n",
      "Epoch 4 [1600/8000 (20%)]\tTraining loss: 0.9279 \tTraining accuracy: 68.1%\n",
      "Epoch 4 [3200/8000 (40%)]\tTraining loss: 0.9651 \tTraining accuracy: 66.7%\n",
      "Epoch 4 [4800/8000 (60%)]\tTraining loss: 0.6999 \tTraining accuracy: 72.2%\n",
      "Epoch 4 [6400/8000 (80%)]\tTraining loss: 0.7983 \tTraining accuracy: 69.4%\n",
      "\n",
      "Test set: Average loss: 0.8792 \tAccuracy: 64.556%\n",
      "\n",
      "Examples: prediction | input\n",
      "68840088# \t three eight six two zero four eight\n",
      "45134#000 \t four five one three four\n",
      "87555557# \t eight one seven six five five seven\n",
      "64933#000 \t six four one three nine\n",
      "54131111# \t five four three eight seven one two one\n",
      "6570099#0 \t six five one zero seven nine\n",
      "74552#000 \t seven five four five two\n",
      "966600#00 \t nine five six eight six zero\n",
      "3901019#0 \t three nine zero one one nine eight\n",
      "4646443#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 5 [0/8000 (0%)]\tTraining loss: 0.6972 \tTraining accuracy: 69.4%\n",
      "Epoch 5 [1600/8000 (20%)]\tTraining loss: 0.7961 \tTraining accuracy: 65.3%\n",
      "Epoch 5 [3200/8000 (40%)]\tTraining loss: 0.6351 \tTraining accuracy: 77.8%\n",
      "Epoch 5 [4800/8000 (60%)]\tTraining loss: 0.6252 \tTraining accuracy: 76.4%\n",
      "Epoch 5 [6400/8000 (80%)]\tTraining loss: 0.7021 \tTraining accuracy: 72.2%\n",
      "\n",
      "Test set: Average loss: 0.7539 \tAccuracy: 70.944%\n",
      "\n",
      "Examples: prediction | input\n",
      "6884008#0 \t three eight six two zero four eight\n",
      "41334#000 \t four five one three four\n",
      "8755557#0 \t eight one seven six five five seven\n",
      "64933#000 \t six four one three nine\n",
      "54513111# \t five four three eight seven one two one\n",
      "657009#00 \t six five one zero seven nine\n",
      "75452#000 \t seven five four five two\n",
      "968660#00 \t nine five six eight six zero\n",
      "3901119#0 \t three nine zero one one nine eight\n",
      "2446463#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 6 [0/8000 (0%)]\tTraining loss: 0.5837 \tTraining accuracy: 75.0%\n",
      "Epoch 6 [1600/8000 (20%)]\tTraining loss: 0.7889 \tTraining accuracy: 73.6%\n",
      "Epoch 6 [3200/8000 (40%)]\tTraining loss: 0.5803 \tTraining accuracy: 77.8%\n",
      "Epoch 6 [4800/8000 (60%)]\tTraining loss: 0.5509 \tTraining accuracy: 73.6%\n",
      "Epoch 6 [6400/8000 (80%)]\tTraining loss: 0.5761 \tTraining accuracy: 79.2%\n",
      "\n",
      "Test set: Average loss: 0.6683 \tAccuracy: 73.778%\n",
      "\n",
      "Examples: prediction | input\n",
      "6882008#0 \t three eight six two zero four eight\n",
      "451334#00 \t four five one three four\n",
      "8715557#0 \t eight one seven six five five seven\n",
      "64933#000 \t six four one three nine\n",
      "54131311# \t five four three eight seven one two one\n",
      "657009#00 \t six five one zero seven nine\n",
      "75552#000 \t seven five four five two\n",
      "9566600#0 \t nine five six eight six zero\n",
      "3501119#0 \t three nine zero one one nine eight\n",
      "24944688# \t two four nine four three six eight\n",
      "\n",
      "Epoch 7 [0/8000 (0%)]\tTraining loss: 0.4571 \tTraining accuracy: 83.3%\n",
      "Epoch 7 [1600/8000 (20%)]\tTraining loss: 0.6666 \tTraining accuracy: 75.0%\n",
      "Epoch 7 [3200/8000 (40%)]\tTraining loss: 0.4692 \tTraining accuracy: 83.3%\n",
      "Epoch 7 [4800/8000 (60%)]\tTraining loss: 0.5049 \tTraining accuracy: 80.6%\n",
      "Epoch 7 [6400/8000 (80%)]\tTraining loss: 0.5329 \tTraining accuracy: 77.8%\n",
      "\n",
      "Test set: Average loss: 0.6427 \tAccuracy: 73.833%\n",
      "\n",
      "Examples: prediction | input\n",
      "8888008#0 \t three eight six two zero four eight\n",
      "45134#000 \t four five one three four\n",
      "8775557#0 \t eight one seven six five five seven\n",
      "64939#000 \t six four one three nine\n",
      "54133311# \t five four three eight seven one two one\n",
      "657009#00 \t six five one zero seven nine\n",
      "75552#000 \t seven five four five two\n",
      "950660#00 \t nine five six eight six zero\n",
      "3501119#0 \t three nine zero one one nine eight\n",
      "2446468#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 8 [0/8000 (0%)]\tTraining loss: 0.4842 \tTraining accuracy: 79.2%\n",
      "Epoch 8 [1600/8000 (20%)]\tTraining loss: 0.5326 \tTraining accuracy: 79.2%\n",
      "Epoch 8 [3200/8000 (40%)]\tTraining loss: 0.3939 \tTraining accuracy: 84.7%\n",
      "Epoch 8 [4800/8000 (60%)]\tTraining loss: 0.8009 \tTraining accuracy: 62.5%\n",
      "Epoch 8 [6400/8000 (80%)]\tTraining loss: 0.5885 \tTraining accuracy: 80.6%\n",
      "\n",
      "Test set: Average loss: 0.7125 \tAccuracy: 73.278%\n",
      "\n",
      "Examples: prediction | input\n",
      "3868208#0 \t three eight six two zero four eight\n",
      "45314#000 \t four five one three four\n",
      "8777557#0 \t eight one seven six five five seven\n",
      "64139#000 \t six four one three nine\n",
      "542123211 \t five four three eight seven one two one\n",
      "6510099#0 \t six five one zero seven nine\n",
      "75455#000 \t seven five four five two\n",
      "9568660#0 \t nine five six eight six zero\n",
      "3501119#0 \t three nine zero one one nine eight\n",
      "2454668#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 9 [0/8000 (0%)]\tTraining loss: 0.3978 \tTraining accuracy: 83.3%\n",
      "Epoch 9 [1600/8000 (20%)]\tTraining loss: 0.4931 \tTraining accuracy: 79.2%\n",
      "Epoch 9 [3200/8000 (40%)]\tTraining loss: 0.4226 \tTraining accuracy: 80.6%\n",
      "Epoch 9 [4800/8000 (60%)]\tTraining loss: 0.4121 \tTraining accuracy: 86.1%\n",
      "Epoch 9 [6400/8000 (80%)]\tTraining loss: 0.4505 \tTraining accuracy: 83.3%\n",
      "\n",
      "Test set: Average loss: 0.5844 \tAccuracy: 76.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "3868408#0 \t three eight six two zero four eight\n",
      "45314#000 \t four five one three four\n",
      "8167557#0 \t eight one seven six five five seven\n",
      "64139#000 \t six four one three nine\n",
      "54122211# \t five four three eight seven one two one\n",
      "657079#00 \t six five one zero seven nine\n",
      "75452#000 \t seven five four five two\n",
      "956660#00 \t nine five six eight six zero\n",
      "3901119#0 \t three nine zero one one nine eight\n",
      "2494668#0 \t two four nine four three six eight\n",
      "\n",
      "Epoch 10 [0/8000 (0%)]\tTraining loss: 0.4134 \tTraining accuracy: 77.8%\n",
      "Epoch 10 [1600/8000 (20%)]\tTraining loss: 0.4520 \tTraining accuracy: 80.6%\n",
      "Epoch 10 [3200/8000 (40%)]\tTraining loss: 0.3432 \tTraining accuracy: 88.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 [4800/8000 (60%)]\tTraining loss: 0.3039 \tTraining accuracy: 90.3%\n",
      "Epoch 10 [6400/8000 (80%)]\tTraining loss: 0.4487 \tTraining accuracy: 84.7%\n",
      "\n",
      "Test set: Average loss: 0.6186 \tAccuracy: 75.389%\n",
      "\n",
      "Examples: prediction | input\n",
      "88624408# \t three eight six two zero four eight\n",
      "45334#000 \t four five one three four\n",
      "8176557#0 \t eight one seven six five five seven\n",
      "64139#000 \t six four one three nine\n",
      "54132211# \t five four three eight seven one two one\n",
      "651079#00 \t six five one zero seven nine\n",
      "75452#000 \t seven five four five two\n",
      "956660#00 \t nine five six eight six zero\n",
      "39011118# \t three nine zero one one nine eight\n",
      "2494648#0 \t two four nine four three six eight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(NUM_INPUTS, NUM_UNITS_ENC).to(device)\n",
    "decoder = DecoderRNN(NUM_UNITS_DEC, NUM_OUTPUTS).to(device)\n",
    "enc_optimizer = optim.RMSprop(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optimizer = optim.RMSprop(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get training set\n",
    "inputs, _, targets_in, targets, targets_seqlen, _, _, _, text_targ = generate(TRAINING_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN)\n",
    "max_target_len = max(targets_seqlen)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "targets_in = torch.tensor(targets_in)\n",
    "unique_text_targets = set(text_targ)\n",
    "\n",
    "# Get validation set\n",
    "val_inputs, _, val_targets_in, val_targets, val_targets_seqlen, _, val_text_in, _, val_text_targ = \\\n",
    "    generate(TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN, invalid_set=unique_text_targets)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_targets = torch.tensor(val_targets)\n",
    "val_targets_in = torch.tensor(val_targets_in)\n",
    "max_val_target_len = max(val_targets_seqlen)\n",
    "test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "\n",
    "# Split training set in batches\n",
    "inputs = [inputs[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets = [targets[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets_in = [targets_in[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "\n",
    "# Quick and dirty - just loop over training set without reshuffling\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_target_len)\n",
    "    _, loss, accuracy = test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "    print('\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'.format(loss, accuracy.item()*100.))\n",
    "\n",
    "    # Show examples\n",
    "    print(\"Examples: prediction | input\")\n",
    "    out, _, _ = test(encoder, decoder, val_inputs[:10], val_targets[:10], val_targets_in[:10], criterion, max_val_target_len)\n",
    "    pred = get_pred(out)\n",
    "    pred_text = [numbers_to_text(sample) for sample in pred]\n",
    "    for i in range(10):\n",
    "        print(pred_text[i], \"\\t\", val_text_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "\n",
    "1. Implement missing code for the network in the *train* function. Your validation accuracy is expected to be <20% at this point.\n",
    "2. These networks implement the GRU-gates. Implement an alternative control utilising a memory mechanism (Hint: LSTM). What do you experience? \n",
    "3. There are some parameters in the model that may be optimized further, what could they be? Achieve >90% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial GRU setup\n",
    "This is from the first run of the model, where the results from the first epoch (average) and the last epoch (average) are given below.\n",
    "- [epoch 1] val acc: 51.389 %\n",
    "- [epoch 1] avg loss: 1.1845\n",
    "\n",
    "- [epoch 10] val acc: 75.389 %\n",
    "- [epoch 10] avg loss: 0.6186\n",
    "\n",
    "I couldn't get the network to work as a LSTM instead of GRU, because of the output dimensionality of the output. I have tried to look into Pytorch's documentation and I couldn't find the fix.\n",
    "\n",
    "Below are the errors shown, and the changes I have tried in hope of fixing the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 8000 from 8000 iterations\n",
      "Generated batch length 200 from 203 iterations\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 200, 48), got (200, 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5d83d8118925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mval_targets_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_targets_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmax_val_target_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_targets_seqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val_target_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Split training set in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8eb5344c71b5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtargets_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         out, loss, accuracy = forward_pass(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len,\n\u001b[0;32m----> 9\u001b[0;31m                                            teacher_forcing=TEACHER_FORCING)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7117b1bb3d59>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(encoder, decoder, x, t, t_in, criterion, max_t_len, teacher_forcing)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0menc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdec_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_h\u001b[0m  \u001b[0;31m# Init hidden state of decoder as hidden state of encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-59cc3f78bae1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Hidden shape [1, batch, embed], last hidden state of the GRU cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# We will feed this last hidden state into the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 147\u001b[0;31m                               'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    148\u001b[0m             check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    149\u001b[0m                               'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 200, 48), got (200, 48)"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(NUM_INPUTS, NUM_UNITS_ENC).to(device)\n",
    "decoder = DecoderRNN(NUM_UNITS_DEC, NUM_OUTPUTS).to(device)\n",
    "enc_optimizer = optim.RMSprop(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optimizer = optim.RMSprop(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get training set\n",
    "inputs, _, targets_in, targets, targets_seqlen, _, _, _, text_targ = generate(TRAINING_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN)\n",
    "max_target_len = max(targets_seqlen)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "targets_in = torch.tensor(targets_in)\n",
    "unique_text_targets = set(text_targ)\n",
    "\n",
    "# Get validation set\n",
    "val_inputs, _, val_targets_in, val_targets, val_targets_seqlen, _, val_text_in, _, val_text_targ = \\\n",
    "    generate(TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN, invalid_set=unique_text_targets)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_targets = torch.tensor(val_targets)\n",
    "val_targets_in = torch.tensor(val_targets_in)\n",
    "max_val_target_len = max(val_targets_seqlen)\n",
    "test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "\n",
    "# Split training set in batches\n",
    "inputs = [inputs[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets = [targets[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets_in = [targets_in[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "\n",
    "# Quick and dirty - just loop over training set without reshuffling\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_target_len)\n",
    "    _, loss, accuracy = test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "    print('\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'.format(loss, accuracy.item()*100.))\n",
    "\n",
    "    # Show examples\n",
    "    print(\"Examples: prediction | input\")\n",
    "    out, _, _ = test(encoder, decoder, val_inputs[:10], val_targets[:10], val_targets_in[:10], criterion, max_val_target_len)\n",
    "    pred = get_pred(out)\n",
    "    pred_text = [numbers_to_text(sample) for sample in pred]\n",
    "    for i in range(10):\n",
    "        print(pred_text[i], \"\\t\", val_text_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the run when changing the network from GRU to LSTM, and it shows an error in the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch length 8000 from 8000 iterations\n",
      "Generated batch length 200 from 202 iterations\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 27, got 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5d83d8118925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mval_targets_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_targets_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmax_val_target_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_targets_seqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val_target_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Split training set in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8eb5344c71b5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtargets_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         out, loss, accuracy = forward_pass(encoder, decoder, inputs, targets, targets_in, criterion, max_t_len,\n\u001b[0;32m----> 9\u001b[0;31m                                            teacher_forcing=TEACHER_FORCING)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7117b1bb3d59>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(encoder, decoder, x, t, t_in, criterion, max_t_len, teacher_forcing)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0menc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdec_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_h\u001b[0m  \u001b[0;31m# Init hidden state of decoder as hidden state of encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-3059fb14b7ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Hidden shape [1, batch, embed], last hidden state of the GRU cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# We will feed this last hidden state into the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n\u001b[1;32m    129\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 130\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 27, got 48"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(NUM_INPUTS, NUM_UNITS_ENC).to(device)\n",
    "decoder = DecoderRNN(NUM_UNITS_DEC, NUM_OUTPUTS).to(device)\n",
    "enc_optimizer = optim.RMSprop(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optimizer = optim.RMSprop(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get training set\n",
    "inputs, _, targets_in, targets, targets_seqlen, _, _, _, text_targ = generate(TRAINING_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN)\n",
    "max_target_len = max(targets_seqlen)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "targets_in = torch.tensor(targets_in)\n",
    "unique_text_targets = set(text_targ)\n",
    "\n",
    "# Get validation set\n",
    "val_inputs, _, val_targets_in, val_targets, val_targets_seqlen, _, val_text_in, _, val_text_targ = \\\n",
    "    generate(TEST_SIZE, min_len=MIN_SEQ_LEN, max_len=MAX_SEQ_LEN, invalid_set=unique_text_targets)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_targets = torch.tensor(val_targets)\n",
    "val_targets_in = torch.tensor(val_targets_in)\n",
    "max_val_target_len = max(val_targets_seqlen)\n",
    "test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "\n",
    "# Split training set in batches\n",
    "inputs = [inputs[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets = [targets[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "targets_in = [targets_in[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] for i in range(TRAINING_SIZE // BATCH_SIZE)]\n",
    "\n",
    "# Quick and dirty - just loop over training set without reshuffling\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(encoder, decoder, inputs, targets, targets_in, criterion, enc_optimizer, dec_optimizer, epoch, max_target_len)\n",
    "    _, loss, accuracy = test(encoder, decoder, val_inputs, val_targets, val_targets_in, criterion, max_val_target_len)\n",
    "    print('\\nTest set: Average loss: {:.4f} \\tAccuracy: {:.3f}%\\n'.format(loss, accuracy.item()*100.))\n",
    "\n",
    "    # Show examples\n",
    "    print(\"Examples: prediction | input\")\n",
    "    out, _, _ = test(encoder, decoder, val_inputs[:10], val_targets[:10], val_targets_in[:10], criterion, max_val_target_len)\n",
    "    pred = get_pred(out)\n",
    "    pred_text = [numbers_to_text(sample) for sample in pred]\n",
    "    for i in range(10):\n",
    "        print(pred_text[i], \"\\t\", val_text_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the error shown, after trying to change the initialization of the network from containing only hidden_size to have both hidden_size and input_size, in hope of fixing the dimensionality from 48 to 27."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
